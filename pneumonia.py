# -*- coding: utf-8 -*-
"""Pneumonia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IIW0E7UQ3OF0-BNirBtnXgk4-wsHmOKO

<h1><center>Pneumonia Detection</center></h1> 
<center>Prof. Predrag Radivojac, Northeastern University, Spring 2020
 </center>  
<center>Basar S. Chowdhury (chowdhury.b@husky.neu.edu),  Mayur Kurup (kurup.m@husky.neu.edu)
</center> 

---
"""

## disable future warnings
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import matplotlib.pyplot as plt
import pydicom
import pandas as pd
from glob import glob
import pylab
import os
import seaborn as sns
from matplotlib.patches import Rectangle
import csv
import random
from skimage import measure
from skimage.transform import resize
import tensorflow as tf
from tensorflow import keras
from matplotlib import pyplot as plt
import gc
from skimage.transform import resize
from keras.models import Sequential
from keras.layers import Dense
from keras.utils.vis_utils import plot_model

## input dir
data_dir = os.path.join(os.getcwd() + '/rsna')

"""###Exploratory Data Analysis : EDA"""

## list all the files in the input folder
print("\n".join(os.listdir(data_dir)))

## load and set file/folder variables
details_class_info_csv = os.path.join(data_dir, 'stage_2_detailed_class_info.csv')
labeled_boxes_csv = os.path.join(data_dir, 'stage_2_train_labels.csv')
train_images_folder = os.path.join(data_dir, 'stage_2_train_images')
test_images = os.path.join(data_dir, 'stage_2_test_images')

## load the csv's as dataframe 
labled_df = pd.read_csv(labeled_boxes_csv)
print("Content of the stage_2_train_labels.csv: \n")
labled_df.head()

class_info_df = pd.read_csv(details_class_info_csv)
print("\n\n\nContent of the stage_2_detailed_class_info.csv:\n")
class_info_df.head()

"""**Description of the files:**    
`stage_2_train_labels.csv` : training set with patientId and labels    
`stage_2_sample_submission.csv`      
`stage_2_test_images` : folder containing test images    
`stage_2_train_images` : folder contaning training images     
`stage_2_detailed_class_info.csv` : contains more details about the patient and lung opacities
"""

def get_dcm_image(patientId, data_type="train"):
  '''returns the path to the corresponding patientId 
  image file path
  '''
  filepath = ''
  if data_type == 'train':
    filepath = os.path.join(data_dir, 'stage_2_train_images/%s.dcm' % patientId)
  else:
    filepath = os.path.join(data_dir, 'stage_2_test_images/%s.dcm' % patientId)

  return filepath

"""#### View files types, content and format"""

## viewing the individual image sample given patientId
def view_individual_patient_image(patientId, 
                                  cmap_value=pylab.cm.gist_gray):
  '''Views the individuals patients image 
  patientId : patient's id
  '''
  dcm_file = get_dcm_image(patientId)
  dcm_data = pydicom.read_file(dcm_file)
  sample_img = dcm_data.pixel_array
  pylab.imshow(sample_img, cmap=cmap_value)
  pylab.axis('off')

## view the content of the dcm file 
pid = labled_df['patientId'][4]
dcm_file = get_dcm_image(pid)
dcm_data = pydicom.read_file(dcm_file)
print("dcm_file format for patientId=4\n")
print(dcm_data)

"""#### View different classes of patient images      
It will help us manually guess the what we are trying to classify and    
what approach we can take.
"""

## view image
print("\n\nimage of patientId=4 with class 'Lung Opacity'")
view_individual_patient_image(pid)

print("\n\nimage of patientId=1 with class 'No Lung Opacity / Not Normal'")
view_individual_patient_image(labled_df['patientId'][1])

print("\n\nimage of patientId=3 with class 'Normal'")
view_individual_patient_image(labled_df['patientId'][3])

print("\n\nimage of patientId=2 with class 'No Lung Opacity / Not Normal'")
view_individual_patient_image(labled_df['patientId'][2])

print("patient with heart condition")
print("\n\nimage of patientId=38 with class 'No Lung Opacity / Not Normal'")
view_individual_patient_image(labled_df['patientId'][38])

## missing half lung
pid_missing = box_df.loc[box_df['patientId'] == "924f4f8b-fc27-4dfd-b5ae-59c40715e150"]
print(pid_missing)
view_individual_patient_image(labled_df['patientId'][14879])

"""**Check missing values**"""

def missing_data(data):
  '''
  '''
  total = data.isnull().sum().sort_values(ascending = False)
  percent = (data.isnull().sum()/data.isnull().count()*100).sort_values(ascending = False)
  return np.transpose(pd.concat([total, percent], axis=1, keys=['Total', 'Percent']))

## check for missing data 'stage_2_train_labels'
missing_data(labled_df)

## check for missing data in stage_2_detailed_class_info
missing_data(class_info_df)

"""#### Shape of the data"""

## view the dimensions, counts
print("Shape of stage_2_detailed_class_info.csv : {0}".format(class_info_df.shape))
print("Unique values : {0}\n\n".format(class_info_df['patientId'].value_counts().shape[0]))

## plot the distribution of classes
class_info_df.groupby('class').size().plot.bar()

print("Shape of stage_2_train_labels.csv : {0}".format(labled_df.shape))
print("Unique values : {0}\n\n".format(labled_df['patientId'].value_counts().shape[0]))
## plot the distribution of classes
labled_df.groupby('Target').size().plot.bar()

## train
print("Total image files in 'stage_2_train_images' : {0}".format(len(os.listdir(train_images_folder))))

"""Total no. of image files in 'stage_2_train_images' : `26684`     
Total no. of records in 'stage_2_train_labels.csv' : `26684`  
Total no. of unique records in 'stage_2_detailed_class_info': `26684`     


They are consistent with each other !!

#### View the distribution of 3 different types of classes
"""

merged_df = labled_df.merge(class_info_df, left_on='patientId', right_on='patientId', how='inner')
print(merged_df.shape)
print("unique values in merged dataframe : {0}".format(len(merged_df['patientId'].unique())))
merged_df.sample(5)

fig, ax = plt.subplots(nrows=1,figsize=(12,6))
tmp = merged_df.groupby('Target')['class'].value_counts()
df = pd.DataFrame(data={'Samples': tmp.values}, index=tmp.index).reset_index()
sns.barplot(ax=ax,x = 'Target', y='Samples',hue='class',data=df, palette='Set1')
plt.title("Distribution of types of classes")
plt.show()

"""#### Combine both the csv"""

combined_df = pd.merge(labled_df, class_info_df, how='inner', on='patientId')
print(combined_df.shape[0], 'combined cases')

# combined_df = pd.concat([labled_df, 
#                         class_info_df.drop('patientId',1)], 1)
# print(combined_df.shape[0], 'combined cases')
# combined_df.sample(10)
combined_svm_df = combined_df.copy()

"""#### Find lungs opacity intervals

We will filter out all the records with box values so that we can   
plot the ranges of the box. This will give us an vague idea of the localization of the target boxes for opacity.
"""

final = combined_df.dropna()  ## this will filter all the records only with boxes
print(final.shape[0], 'combined cases')
final.sample(5)

sns.set_style('whitegrid')
plt.figure()
fig, ax = plt.subplots(2,2,figsize=(10,10))
sns.distplot(final['x'],kde=True,bins=30, color="orange", ax=ax[0,0])
sns.distplot(final['y'],kde=True,bins=30, color="green", ax=ax[0,1])
sns.distplot(final['width'],kde=True,bins=30, color="red", ax=ax[1,0])
sns.distplot(final['height'],kde=True,bins=30, color="blue", ax=ax[1,1])

locs, labels = plt.xticks()
plt.tick_params(axis='both', which='major', labelsize=12)
plt.show()

## Centers of rectangle

fig, ax = plt.subplots(1,1,figsize=(5,5))
final1 = final.sample(1000)
final1['x_center'] = final1['x'] + final1['width'] / 2
final1['y_center'] = final1['y'] + final1['height'] / 2
plt.title("Lung Opacity rectangles")
final1.plot.scatter(x='x_center', y='y_center', xlim=(0,1024), ylim=(0,1024), ax=ax, alpha=0.7, marker=".", color="green")
for i, sample in final1.iterrows():
    ax.add_patch(Rectangle(xy=(sample['x'], sample['y']),
                width=sample['width'],height=sample['height'],alpha=3.5e-3, color="yellow"))
plt.show()

final.groupby(['class', 'Target']).size().reset_index(name='Patient Count')

box_df = combined_df.groupby('patientId').size().reset_index(name='boxes')
combined_df = pd.merge(combined_df, box_df, on='patientId')
box_df.groupby('boxes').size().reset_index(name='patients')

box1_df = final.groupby('patientId').size().reset_index(name='boxes1')
final = pd.merge(final, box1_df, on='patientId')
box1_df.groupby('boxes1').size().reset_index(name='patients')

print(box_df.iloc[8])

"""#### View the individual images with different color maps"""

pid_45 = box_df['patientId'][45]
view_individual_patient_image(pid_45, cmap_value=pylab.cm.inferno)

view_individual_patient_image(pid_45, cmap_value=pylab.cm.bone)



view_individual_patient_image(pid_45, cmap_value=pylab.cm.viridis)

def parse_data_dict(df):
    extract_box = lambda row: [row['y'], row['x'], row['height'], row['width']]

    parsed = {}
    for n, row in df.iterrows(): 
        pid = row['patientId']
        if pid not in parsed:
            parsed[pid] = {
                'dicom': get_dcm_image(pid),
                'label': row['Target'],
                'boxes': []}

        if parsed[pid]['label'] == 1:
            parsed[pid]['boxes'].append(extract_box(row))

    return parsed

parsed = parse_data_dict(labled_df)
print(len(parsed.keys()))

# print(parsed['003d8fa0-6bf1-40ed-b54c-ac657f8495c5']) ## normal 
# print(parsed['00704310-78a8-4b38-8475-49f4573b2dbb']) ## opaque

"""#### Visualize the boxes"""

def overlay_box(pixels, box, rgb, stroke=8):
    #get integers coordinates
    box = [int(b) for b in box]
    
    #get x,y coordinates
    y1, x1, height, width = box
    y2 = y1 + height 
    x2 = x1 + width

    pixels[y1:y1 + stroke, x1:x2] = rgb
    pixels[y2:y2 + stroke, x1:x2] = rgb
    pixels[y1:y2, x1:x1 + stroke] = rgb
    pixels[y1:y2, x2:x2 + stroke] = rgb

    return pixels

def construct_boxes(image, size=(20,10)):
    '''Create boxes using the lables information of 
    boxes given in stage_2_train_labels.csv
    '''
    fig=plt.figure(figsize=size)
    d = pydicom.read_file(image['dicom'])
    pixels = d.pixel_array
    #Convert from 3d for rgb pixels
    pixels = np.stack([pixels] * 3, axis=2)

    for box in image['boxes']:
        rgb = [0,255,0]
        pixels = overlay_box(pixels=pixels, box=box, rgb=rgb, stroke=8)
    pylab.imshow(pixels, cmap=pylab.cm.viridis)
    pylab.axis('off')
    plt.show()

construct_boxes(parsed['01aad2a6-3b93-45e3-bf37-2d73348cb6fc'])

construct_boxes(parsed['00704310-78a8-4b38-8475-49f4573b2dbb'])

construct_boxes(parsed['00f08de1-517e-4652-a04f-d1dc9ee48593'])

construct_boxes(parsed['00f08de1-517e-4652-a04f-d1dc9ee48593'])

pneumonia_locations = {}
# load table
with open(labeled_boxes_csv, mode='r') as infile:
    # open reader
    reader = csv.reader(infile)
    # skip header
    next(reader, None)
    # loop through rows
    for rows in reader:
        # retrieve information
        filename = rows[0]
        location = rows[1:5]
        pneumonia = rows[5]
        # if row contains pneumonia add label to dictionary
        # which contains a list of pneumonia locations per filename
        if pneumonia == '1':
            # convert string to float to int
            location = [int(float(i)) for i in location]
            # save pneumonia location in dictionary
            if filename in pneumonia_locations:
                pneumonia_locations[filename].append(location)
            else:
                pneumonia_locations[filename] = [location]

print(len(pneumonia_locations))

"""#### Split the dataset into train and test"""

## train
filenames = os.listdir(train_images_folder)
print("Total image files in 'stage_2_train_images' : {0}".format(len(filenames)))

## test 
filenames_test = os.listdir(test_images)
print("Total image files in 'stage_2_train_images' : {0}".format(len(filenames_test)))


# split into train and test filenames by 80/20
test = int(len(filenames) * 0.2)
train = filenames[test:]
test = filenames[:test]
print('Train :', len(train))
print('Test : ', len(test))

"""### Convolutional Neural Network

**Data augmentations**    
Images can vary in dimensions and rotation, we need to to take care of the 
image augmentations while training. These augmentation includes the  
* Resizing 
* Rotation 
* Horizontal flips     

We will be using the `keras.utils.Sequence` and implement it to generate the data efficiently.
"""

'''Generic class to augment the image data
Referenced from official documentations 
with batch mode
'''

class Generator(keras.utils.Sequence):
    
    def __init__(self, folder, 
                 filenames, 
                 pneumonia_locations=None, 
                 batch_size=32, 
                 image_size=320, 
                 shuffle=True, 
                 augment=False, 
                 predict=False):
        self.folder = train_images_folder
        self.augment = augment
        self.filenames = filenames
        self.pneumonia_locations = pneumonia_locations
        self.batch_size = batch_size
        self.image_size = image_size
        self.shuffle = shuffle
        self.predict = predict
        self.on_epoch_end()
        
    def __load__(self, filename):
        # diacom as array
        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array
        msk = np.zeros(img.shape)
        ## discard file extension
        filename = filename.split('.')[0]

        ### if image has pnemonia target then extract the box
        if filename in pneumonia_locations:
            for location in pneumonia_locations[filename]:
                ## set '1' if it has pneumonia
                x, y, w, h = location
                msk[y:y+h, x:x+w] = 1
        ## horizontal flip
        if self.augment and random.random() > 0.5:
            img = np.fliplr(img)
            msk = np.fliplr(msk)
        ## resize
        img = resize(img, (self.image_size, self.image_size), mode='reflect')
        msk = resize(msk, (self.image_size, self.image_size), mode='reflect') > 0.5
        img = np.expand_dims(img, -1)
        msk = np.expand_dims(msk, -1)
        return img, msk
    
    def __loadpredict__(self, filename):
        ## diacom as array
        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array
        # resize image
        img = resize(img, (self.image_size, self.image_size), mode='reflect')
        # add trailing channel dimension
        img = np.expand_dims(img, -1)
        return img
    
    def __getitem__(self, idx):
        # set batch size
        filenames = self.filenames[idx*self.batch_size:(idx+1)*self.batch_size]
        # predict mode: return images and filenames
        if self.predict:
            # load files
            imgs = [self.__loadpredict__(filename) for filename in filenames]
            # create numpy batch
            imgs = np.array(imgs)
            return imgs, filenames
        
        ## return images and masks
        else:
            items = [self.__load__(filename) for filename in filenames]
            imgs, msks = zip(*items)
            # create numpy batch
            imgs = np.array(imgs)
            msks = np.array(msks)
            return imgs, msks
        
    def on_epoch_end(self):
        if self.shuffle:
            random.shuffle(self.filenames)
            
    def __len__(self):
        if self.predict:
            # return everything
            return int(np.ceil(len(self.filenames) / self.batch_size))
        else:
            # return full batches only
            return int(len(self.filenames) / self.batch_size)

BATCH_SIZE = 16
IMAGE_SIZE = 320

def downSample(channels, inputs):
    x = keras.layers.Conv2D(channels, 1, padding='same', use_bias=False)(inputs)
    x = keras.layers.BatchNormalization(momentum=0.9)(x)
    x = keras.layers.LeakyReLU(0)(x)
    x = keras.layers.MaxPool2D(2)(x)
    return x

def resNet(channels, inputs):
    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)
    x = keras.layers.LeakyReLU(0)(x)
    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)
    return keras.layers.add([x, inputs])

def myRESNET(input_size, channels, blocks=2, depth=3):
    #Input layer
    inputs = keras.Input(shape=(input_size, input_size, 1))
    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(inputs)
    #Residual layer
    for d in range(depth):
        channels = channels * 2
        x = downSample(channels, x)
        for b in range(blocks):
            x = resNet(channels, x)
    # output
    x = keras.layers.BatchNormalization(momentum=0.9)(x)
    x = keras.layers.LeakyReLU(0)(x)
    x = keras.layers.Conv2D(256, 1, activation=None)(x)
    x = keras.layers.BatchNormalization(momentum=0.9)(x)
    x = keras.layers.LeakyReLU(0)(x)
    x = keras.layers.Conv2DTranspose(128, (8,8), (4,4), padding="same", activation=None)(x)
    x = keras.layers.BatchNormalization(momentum=0.9)(x)
    x = keras.layers.LeakyReLU(0)(x)
    x = keras.layers.Conv2D(64,1, padding="same", activation=None)(x)
    x = keras.layers.BatchNormalization(momentum=0.9)(x)
    x = keras.layers.LeakyReLU(0)(x)
    x = keras.layers.Conv2D(1, 1, activation='sigmoid')(x)
    outputs = keras.layers.AveragePooling2D(pool_size=(2, 2), strides=None, padding='valid', data_format=None)(x)
    outputs = keras.layers.UpSampling2D(2**(depth-2))(x)
    model = keras.Model(inputs=inputs, outputs=outputs)
    return model

## plot the model
from keras.models import Sequential
from keras.layers import Dense
from keras.utils.vis_utils import plot_model

model = myRESNET(input_size=320, channels=32, blocks=2, depth=3)
plot_model(model, to_file='cnn_model.png', show_shapes=True, show_layer_names=True, dpi=90)

# create network and compiler
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

#annealing cosine learning
def cosine_annealing(x):
    lr = 0.002
    epochs = 15
    return lr*(np.cos(np.pi*x/epochs)+1.)/2
learning_rate = tf.keras.callbacks.LearningRateScheduler(cosine_annealing)

# create train and validation generators
train_gen = Generator(train_images_folder, train, pneumonia_locations, batch_size=16, image_size=320, shuffle=True, augment=True, predict=False)
test_gen = Generator(train_images_folder, test, pneumonia_locations, batch_size=16, image_size=320, shuffle=False, predict=False)

print(model.summary())



myRESNET = model.fit_generator(train_gen, validation_data=test_gen, callbacks=[learning_rate], epochs=1, shuffle=True)

duplicate_RESNET = myRESNET

print(myRESNET.history.keys())

print(myRESNET.history['accuracy'])
print(myRESNET.history['val_accuracy'])

"""### Support vector machine"""

## from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.model_selection import StratifiedKFold
from sklearn import datasets
from sklearn.metrics import auc
from sklearn.metrics import plot_roc_curve
import numpy as np
import pandas as pd
from numpy import interp
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

combined_svm_df.shape
combined_svm_df.sample(20)
forSVMFinal_df = combined_svm_df.drop('class', axis = 1).copy()
forSVMFinal_df.sample(5)

## fresh load file again and resets the variables
## load and set file/folder variables
details_class_info_csv = os.path.join(data_dir, 'stage_2_detailed_class_info.csv')
labeled_boxes_csv = os.path.join(data_dir, 'stage_2_train_labels.csv')
train_images_folder = os.path.join(data_dir, 'stage_2_train_images')
test_images = os.path.join(data_dir, 'stage_2_test_images')

## load the csv's as dataframe 
labled_df_tmp = pd.read_csv(labeled_boxes_csv)
print("Content of the stage_2_train_labels.csv: \n")
labled_df_tmp.head()

## second csv
class_info_df_tmp = pd.read_csv(details_class_info_csv)
print("\n\n\nContent of the stage_2_detailed_class_info.csv:\n")
class_info_df_tmp.head()

df = pd.merge(left = class_info_df_tmp, right = labled_df_tmp, how = 'left', on = 'patientId')

del class_info_df_tmp, labled_df_tmp
gc.collect()

df = df.drop_duplicates()
df_meta = df.drop('class', axis = 1).copy()
df_meta.sample(20)

## if df_meta.pkl pickle is not available then run the following.
## it takes couple of hrs to parse through each file
dcm_columns = None
for n, pid in enumerate(df_meta['patientId'].unique()):
    dcm_file = get_dcm_image(pid)
    dcm_data = pydicom.read_file(dcm_file)
    
    if not dcm_columns:
        dcm_columns = dcm_data.dir()
        dcm_columns.remove('PixelSpacing')
        dcm_columns.remove('PixelData')
    
    for col in dcm_columns:
        if not (col in df_meta.columns):
            df_meta[col] = np.nan
        index = df_meta[df_meta['patientId'] == pid].index
        df_meta.loc[index, col] = dcm_data.data_element(col).value
        
    del dcm_data
    
gc.collect()

df_meta.head()

## save to pickle so that we dont have to parse the images again
## which takes more than 2hrs
df_meta.to_pickle("./df_meta.pkl")

## read from pickle 
df_meta = pd.read_pickle("./df_meta.pkl")

print(df_meta.head())

def get_meta_data(pid, columns):
    dicom = pydicom.read_file(get_dcm_image(pid))
    wantedColumn = getattr(dicom, columns)
    return wantedColumn

"""##### Adding few important columns from the image metadata."""

## important columns - should have some variance and distribution
columns = ['PatientSex', 'PatientAge', 'ViewPosition']
for i in columns:
    forSVMFinal_df[i] = forSVMFinal_df['patientId'].apply(lambda l: get_meta_data(l, i))
forSVMFinal_df['PatientAge'] = forSVMFinal_df['PatientAge'].apply(pd.to_numeric, errors='coerce')
forSVMFinal_df['PatientAge'] = forSVMFinal_df['PatientAge'].apply(lambda l: l if l<120 else np.nan)

forSVMFinal_df.head()

svmDuplicate_df = forSVMFinal_df

svmDuplicate_df.sample(20)

## mapping the categorical values to the numeric
svmDuplicate_df['PatientSex'] = svmDuplicate_df['PatientSex'].map({'F': 0, 'M': 1}) 
svmDuplicate_df['ViewPosition'] = svmDuplicate_df['ViewPosition'].map({'PA': 0, 'AP': 1})

forSVMFinal_df.head()

svm_df = forSVMFinal_df[['PatientSex', 'PatientAge', 'ViewPosition', 'Target']]

svm_df.sample(20)

## save the metadata information in csv
METADATA_FILE = "svm_metadat_df.csv"
svm_df = svm_df.dropna()
svm_df.to_csv(METADATA_FILE, index = False)
print(svm_df.shape)

## finally traning the SVM 

image_metadata_df = pd.read_csv(METADATA_FILE);
array = image_metadata_df.values
X = array[:,0:3]
y = array[:,3]


cv = StratifiedKFold(n_splits=10)
svm_model = SVC(kernel='rbf', gamma=0.05, C=1.0)
aucs = []
tprs = []
mean_fpr = np.linspace(0, 1, 100)

fig, ax = plt.subplots()
for i, (train, test) in enumerate(cv.split(X, y)):
    svm_model.fit(X[train], y[train])
    figure = plot_roc_curve(svm_model, X[test], y[test],
                            name='ROC fold {}'.format(i),
                            alpha=0.3, 
                            lw=1,
                            ax=ax)
    interp_tpr = interp(mean_fpr, figure.fpr, figure.tpr)
    interp_tpr[0] = 0.0
    tprs.append(interp_tpr)
    aucs.append(figure.roc_auc)
    print('AUC = ', end =""),
    print(float(figure.roc_auc))


mean_tpr = np.mean(tprs, axis=0)
mean_tpr[-1] = 1.0
mean_auc = auc(mean_fpr, mean_tpr)
print('Mean AUC = ', end ="")
print(mean_auc)
ax.plot(mean_fpr, mean_tpr, color='b',
        label=r'Mean ROC (AUC = %0.2f)' % (mean_auc),
        lw=2, alpha=.8)

std_tpr = np.std(tprs, axis=0)
tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
tprs_lower = np.maximum(mean_tpr - std_tpr, 0)


ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],
       title="ROC")
ax.legend(loc="lower right")
plt.show()

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True, random_state=0)
svm_model = SVC(kernel='rbf', gamma=0.1, C=1.0)
svm_model.fit(x_train, y_train)
predictions = svm_model.predict(x_test)
score = svm_model.score(x_test, y_test)
print('Accuracy =',score)

"""### Logistic Regression"""

## imports 
from sklearn.model_selection import StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn import datasets
from sklearn.metrics import auc
from sklearn.metrics import roc_curve
from sklearn.metrics import plot_roc_curve
import numpy as np
import pandas as pd
from numpy import interp
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

image_data = pd.read_csv(METADATA_FILE);
array = image_data.values
X = array[:,0:3]
y = array[:,3]
n_samples, n_features = X.shape


# 10 fold cross-validation and plot ROC curves
cv = StratifiedKFold(n_splits=10)
classifier = LogisticRegression(max_iter=1000)
aucs = []
tprs = []
mean_fpr = np.linspace(0, 1, 100)

fig, ax = plt.subplots()
for i, (train, test) in enumerate(cv.split(X, y)):
    classifier.fit(X[train], y[train])
    figure = plot_roc_curve(classifier, X[test], y[test],
                         name='ROC fold {}'.format(i),
                         alpha=0.3, lw=1, ax=ax)
    interp_tpr = interp(mean_fpr, figure.fpr, figure.tpr)
    interp_tpr[0] = 0.0
    tprs.append(interp_tpr)
    aucs.append(figure.roc_auc)
    print('AUC = ', end =""),
    print(float(figure.roc_auc))


mean_tpr = np.mean(tprs, axis=0)
mean_tpr[-1] = 1.0
mean_auc = auc(mean_fpr, mean_tpr)
print('Mean AUC = ', end ="")
print(mean_auc)
ax.plot(mean_fpr, mean_tpr, color='b',
        label=r'Mean ROC (AUC = %0.2f)' % (mean_auc),
        lw=2, alpha=.8)

std_tpr = np.std(tprs, axis=0)
tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
tprs_lower = np.maximum(mean_tpr - std_tpr, 0)


ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05],
       title="ROC")
ax.legend(loc="lower right")
plt.show()

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True, random_state=0)
classifier.fit(x_train, y_train)
predictions = classifier.predict(x_test)
score = classifier.score(x_test, y_test)
print('Accuracy =',score)

